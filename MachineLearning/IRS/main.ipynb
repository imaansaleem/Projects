{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information Retrieval System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information retrieval is the process of obtaining information system resources that are relevant to an information need from a collection of those resources. The core purpose of this assignment is to give you the flavor of IRS. You need to follow some steps listed below and in the end, you'll be able to build your own small IRS. So, let's start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required imports\n",
    "import numpy as np\n",
    "import fnmatch\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have 3 files containing data :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"This is my book\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/f1.png?raw=true)\n",
    "![\"This is my pen\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/f2.png?raw=true)\n",
    "![\"This is book is intersting\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/f3.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 Create Files with Dummy data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to create few files with dummy data of your own choice as shown above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 Traverse Directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now, You have to traverse the directories and store all the files into a dict type variable(files_dict). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we have initialized some variables, you can add more if required.\n",
    "\n",
    "file_count = 0             # file_count to count number of files\n",
    "files_dict = {}            # files_dic to store count of every file    \n",
    "unique_word_set = set()    # unique_word_set to store all the unique words in a set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This code uses the os and fnmatch modules to list all the files in the current directory that have the .txt extension.\n",
    "for file in os.listdir('.'):  # lists all the files in the current directory\n",
    "    # If format of file matches with parameter which means any file name that starts with f and ends with .txt.\n",
    "    if fnmatch.fnmatch(file, 'f*.txt'):\n",
    "        # If the file name matches, the condition is True, and the file count is incremented\n",
    "        file_count += 1\n",
    "        # Place the file name inside files_dict\n",
    "        files_dict[file] = file_count-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying the count of files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Number  of files\n",
      " 3\n"
     ]
    }
   ],
   "source": [
    "# Print Total Number  of files\n",
    "print(\"\\nTotal Number  of files\\n\", file_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying Dictionary containing all files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dictionary containing  files\n",
      " {'f1.txt': 0, 'f2.txt': 1, 'f3.txt': 2}\n"
     ]
    }
   ],
   "source": [
    "#print Dictionary containing  files\n",
    "print(\"\\nDictionary containing  files\\n\", files_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 Extract Unique Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code to print all the unique words in every file and store them in a set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'interesting', 'my', 'book', 'this', 'is', 'pen'}\n",
      "\n",
      "Count of files:  3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# open all files in files_dict\n",
    "for files in files_dict:\n",
    "    # opening in read mode\n",
    "    with open(files, 'r') as f:\n",
    "        # Read the contents of the file, convert to lowercase, and split into words \n",
    "        words = f.read().lower().split()\n",
    "        # add unique words to the set\n",
    "        unique_word_set.update(words)\n",
    "\n",
    "#print set\n",
    "print(unique_word_set)\n",
    "\n",
    "#print Number of files\n",
    "print(\"\\nCount of files: \", file_count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Expected Output of unique words\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/o1.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 Create Term Document Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Term-Doc-matrix using Bag of word approach.and display its contents initially and finally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Term doc matrix such that colmns will be unique words and all the files will be rows\n",
    "# Write code to count all the unique words appearances in all the files and store it in a dictionary for words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0]]\n",
      "{'this': 0, 'is': 1, 'my': 2, 'book': 3, 'pen': 4, 'interesting': 5}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Create the term-document matrix\n",
    "term_doc_matrix = [[] for i in range(file_count)]\n",
    "\n",
    "for i in range(file_count):\n",
    "    # Initialize a row of zeros for the matrix\n",
    "    term_doc_matrix[i] = [0] * len(unique_word_set)\n",
    "print(term_doc_matrix)\n",
    "\n",
    "# Initialize the dictionary to store the word counts\n",
    "words_dictionary = {}\n",
    "\n",
    "# variable to assign unique index to words_dictionary\n",
    "count = 0\n",
    "\n",
    "# Loop over all the files\n",
    "for file_name in files_dict.keys():\n",
    "    # Open the file in read mode\n",
    "    with open(file_name, 'r') as f:\n",
    "        # Read the file's contents and split into words\n",
    "        words = f.read().lower().split()\n",
    "\n",
    "        # Loop over each word and update its count in the dictionary\n",
    "        for word in words:\n",
    "            # if word is not already in dictionary\n",
    "            if word not in words_dictionary:\n",
    "                # place it in the dictionary with unique index as value\n",
    "                words_dictionary[word] = count\n",
    "                # increment index\n",
    "                count += 1\n",
    "# print dictionary\n",
    "print(words_dictionary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Expected Output of unique words\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/o2.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5 Fill Term Document Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the term doc matrix by checking if the unique word exists in a file or not\n",
    "# If it exists then substitute a 1 in term_doc_matrix (eg : TERM_DOC_MATRIX[file][word] = 1 ) \n",
    "# Do the same for all the files present in the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Term-document matrix:\n",
      " [[1, 1, 1, 1, 0, 0], [1, 1, 1, 0, 1, 0], [0, 1, 1, 1, 0, 1]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Loop over all the files in the dictionary\n",
    "for file_name in files_dict.keys():\n",
    "    # Open the file in read mode\n",
    "    with open(file_name, 'r') as f:\n",
    "        # Read the contents of the file, convert to lowercase, and split into words\n",
    "        words = f.read().lower().split()\n",
    "        # go for every word in words\n",
    "        for word in words:\n",
    "            # if word is found in word_dictionary\n",
    "            if word in words_dictionary.keys():\n",
    "                # Get the index of the word in the words dictionary\n",
    "                # files_dict[file_name] gives index of word from file name dictionary\n",
    "                term_doc_matrix[files_dict[file_name]][words_dictionary[word]] = 1\n",
    "\n",
    "# Print the term-document matrix\n",
    "print(\"\\nTerm-document matrix:\\n\", term_doc_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Expected Output of unique words\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/o4.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6 Ask for a user Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For user query make a column vector of length of all the unique words present in a set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Vector:\n",
      " [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Create a column vector of zeros of length equal to the number of unique words\n",
    "query_vector = np.zeros((len(unique_word_set), 1))\n",
    "\n",
    "# print query_vector\n",
    "print(\"Query Vector:\\n\", query_vector)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Expected Output of unique words\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/o5.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = input(\"\\nWrite something for searching  \")\n",
    "# Check every word of query if it exists in the set of unique words or not\n",
    "# If exixts then increment the count of that word in word dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Write something for searching  my pen\n",
      "\n",
      "Query vector:\n",
      " [[0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Taking input\n",
    "query = input(\"\\nWrite something for searching  \")\n",
    "\n",
    "# split all the words passed in query\n",
    "query_words = query.lower().split()\n",
    "\n",
    "# for each word in query\n",
    "for word in query_words:\n",
    "    # if word is present in unique word set\n",
    "    if word in unique_word_set:\n",
    "        # increment the query vector\n",
    "        query_vector[words_dictionary[word]] += 1\n",
    "\n",
    "# print query vector\n",
    "print(\"\\nQuery vector:\\n\", query_vector)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Expected Output of unique words\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/o6.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7 Display Resultant Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display \n",
    "1. Resultant vector.\n",
    "2. Max value in resultant vector.\n",
    "3. Index of max value in resultant vector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result:\n",
      " [[1.]\n",
      " [2.]\n",
      " [1.]]\n",
      "Max_index:\n",
      " 1\n",
      "Max:\n",
      " [2.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# multiply term_doc_matrix with query_vector using dot product\n",
    "resultant = np.dot(term_doc_matrix, query_vector)\n",
    "\n",
    "# find max value from the resultant vector\n",
    "maxValue = max(resultant)\n",
    "\n",
    "# find max index from the resultant vector\n",
    "max_index = np.argmax(resultant)\n",
    "\n",
    "# print Resultant vactor\n",
    "print(\"Result:\\n\", resultant)\n",
    "\n",
    "# print Max Index\n",
    "print(\"Max_index:\\n\", max_index)\n",
    "\n",
    "# print Max value\n",
    "print(\"Max:\\n\", maxValue)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Expected Output of unique words\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/o7.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8 Display the contents of file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write the code to identify the file_name having maximum value in the resultant vector and display its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the file name with the maximum value in the resultant vector\n",
    "for key, value in files_dict.items():\n",
    "    # if max index of query vector matches with the files_dict values \n",
    "    if value == max_index:\n",
    "        # Print the contents of the file\n",
    "        print(\"\\nContents of the file with maximum value in the resultant vector:\", key)\n",
    "        \n",
    "        # open the file against the file name in read mode\n",
    "        with open(key, 'r') as f:\n",
    "            # print the read data\n",
    "            print(f.read())\n",
    "        break\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
